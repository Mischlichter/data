name: Image Metadata Extraction and Webpage Verification

on:
  push:
    paths:
      - 'gallerycom/**/*.jpg'

jobs:
  extract-metadata:
    runs-on: ubuntu-latest
    outputs:
      filenames: ${{ steps.extract_filenames.outputs.filenames }}

    steps:
      - name: Checkout Repository
        uses: actions/checkout@v2

      - name: Set up Python
        uses: actions/setup-python@v2
        with:
          python-version: '3.x'

      - name: Install Python Dependencies
        run: |
          pip install Pillow

      - name: Install exiftool
        run: |
          sudo apt-get update
          sudo apt-get install -y exiftool

      - name: Run Metadata Extraction Script
        run: python lib/library_and_pages_x.py

      - name: Extract Filenames of Pushed JPGs
        id: extract_filenames
        run: |
          echo "Files Changed:"
          FILES=$(git diff --name-only ${{ github.event.before }} ${{ github.event.after }} | grep '\.jpg$')
          echo $FILES
          HTML_FILES=$(echo "$FILES" | sed 's/.jpg$/.html/' | xargs -n 1 basename)
          echo "::set-output name=filenames::$HTML_FILES"

      - name: Commit and Push Changes
        run: |
          git config --global user.name 'Mischlichter'
          git config --global user.email 'alex.stephan.weimar@web.de'
          git add lib/metadata.json
          git add docs/sharing/*.html
          git add docs/sharing/*_favicon.ico
          git commit -m "Update image metadata, HTML pages, and favicons" || echo "No changes to commit"
          git push || echo "Failed to push changes. Check for potential conflicts or issues."

  check-website:
    needs: extract-metadata
    runs-on: ubuntu-latest

    steps:
      - name: Check if Pages are Live
        run: |
          for filename in ${{ needs.extract-metadata.outputs.filenames }}
          do
            url="https://www.hogeai.com/sharing/${filename}"
            echo "Checking URL: $url"
            max_retries=10
            for ((i=1; i<=max_retries; i++)); do
              if curl --output /dev/null --silent --head --fail "$url"; then
                echo "$url is live!"
                break
              else
                echo "$url is not yet live. Retrying in 30 seconds..."
                sleep 30
              fi
            done
            if [ $i -gt $max_retries ]; then
              echo "Failed to verify $url after $max_retries attempts."
              exit 1
            fi
          done
